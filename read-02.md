Big O notation is a form of notation that describes technical aspects of an algorythm
O(1) takes the same amount of time and storage regardless of input size
O(N) amount of time and space grows proportional to the size of the input
O(N^2) ??? seems the same as ^
O(2^N) doubles with each addition of data
O(log N) I can't tell if what it's describing is called a binary search or a logarithm, but I've seen it before. Just viewing the center realizing it's too much so ignoring the high end and repeating with the remaining data until we find what we're looking for or we run out of data.